# See tools/run.sh for the env vars used in this config
results_dir: ${CONTAINER_RESULTS_DIR}
artifacts_dir: ${CONTAINER_ARTIFACTS_DIR}
datasets:
  - name: cc
    formats:
    - type: json
      path: ${CONTAINER_DATASETS_DIR}/sample/25de70f6c6a6.jsonl
    - type: parquet
      path: ${CONTAINER_DATASETS_DIR}/sample/25de70f6c6a6.parquet

default_timeout_s: 7200

# Optional sinks
sinks:
  - name: mlflow
    tracking_uri: ${MLFLOW_TRACKING_URI}
    experiment: ray-curator-common-crawl
    enabled: false
  - name: slack
    webhook_url: ${SLACK_WEBHOOK_URL}
    enabled: true
  - name: gdrive
    enabled: false

# Whether to delete scratch dirs after each run
delete_scratch: true

entries:
  - name: cc_main_raydata
    script: common_crawl_benchmark.py
    args: >-
      --download_path {session_entry_dir}/scratch/downloads
      --output_path {session_entry_dir}/scratch/output
      --output_format parquet
      --crawl_type main
      --start_snapshot 2023-01
      --end_snapshot 2023-10
      --html_extraction justext
      --url_limit 10
      --add_filename_column
      --executor ray_data
    timeout_s: 20000
    ray:
      num_cpus: 64
      num_gpus: 0
      enable_object_spilling: false
  - name: removal_main_raydata
    script: removal_benchmark.py
    args: >-
      --download_path {session_entry_dir}/scratch/downloads
      --output_path {session_entry_dir}/scratch/output
      --output_format parquet
      --crawl_type main
      --start_snapshot 2023-01
      --end_snapshot 2023-10
      --html_extraction justext
      --url_limit 10
      --add_filename_column
      --executor ray_data
    timeout_s: 20000
    ray:
      num_cpus: 64
      num_gpus: 0
      enable_object_spilling: false
